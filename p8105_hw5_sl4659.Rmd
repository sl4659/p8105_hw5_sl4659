---
title: "p8105_hw5_sl4659"
author: "Shenglin Liu"
date: "10/31/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1
```{r Problem1}
library(tidyverse)
library(rvest)
library(broom)

set.seed(20191029)
# load the iris dataset from the tidyverse package 
# introduce some missing values in each column
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
# function that takes a vector as an argument; replaces missing values using the rules instructed
mis_replace = function(x) {
  output = vector(length = length(x))
  for (i in 1:length(x)) {
    if (is.numeric(x[i])) {
      mean = mean(x[!is.na(x)])
      if (is.na(x[i])) {
        output[i] = mean
      } else {
        output[i] = x[i]
      }
    } else if (is.character(x[i])) {
      if (is.na(x[i])) {
        output[i] = "virginica"
      } else {
        output[i] = x[i]
      }
    }
  }
  output
}
# apply mis_replace to the columns of iris_with_missing using a map statement
iris_fixed = map(iris_with_missing, mis_replace) %>%
  # convert list to data frame
  as.data.frame()
```

## Problem 2
```{r Problem2, message = FALSE}
# produce a character vector of the names of files in the data directory
file_ls = list.files("./data")
file_vec = paste("./data/", file_ls, sep = "")
# assign names to each element
names(file_vec) = file_ls
# apply read_csv to the each file using a map statement
study_df = map_df(.x = file_vec, ~ read_csv(file = .x), .id = "file") %>%
  mutate(
    arm = substring(file, 1, 3),
    subject_id = as.integer(substring(file, 5, 6))
  )
# tidy weekly observations
study_tidy_df = pivot_longer(
  study_df, 
  week_1:week_8,
  names_to = "week", 
  names_prefix = "week_",
  values_to = "value")
study_tidy_df$week = as.integer(study_tidy_df$week)
# multiple groups with one aesthetic
ggplot(data = study_tidy_df, aes(x = week, y = value)) + 
# the group aesthetic maps a different line for each subject
  geom_line(aes(group = file, colour = factor(arm))) +
# title, label and caption
  labs(
    title = "Weekly observations on each subject over time",
    x = "Week",
    y = "Value",
    caption = "Data from p8105.com/homework_5.html"
  )
```

From the spaghetti plot, we can conlude that subjects in the experiment group generally experienced an increase in our measured variables of interest during the 8 week observation period, while the control group experienced no obvious changes in values.

## Problem 3
```{r Problem3Part1}
# write a function to simulate data from a simple linear regression
# fit the regression model
# return estimates of regression coefficients
set.seed(19951029)
sim_regression = function(n = 30, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 50)
  )
  ls_fit = lm(y ~ x, data = sim_data)
  # use tidy to obtain the estimate and p-value
  ls_tidy = tidy(ls_fit, conf.int = TRUE, conf.level = 0.95)
  tibble(
    beta1_hat = ls_tidy$estimate[2],
    p_value = ls_tidy$p.value[2]
  )
}
# write a function to generate n datasets from the model
sim_ite = function(n=10000, beta1) {
  sim_results = rerun(n, sim_regression(beta1 = beta1)) %>% 
    bind_rows()
}
# case: beta1 = 0
zero_df = sim_ite(beta1 = 0)
# case: beta1 = 1, 2, 3, 4, 5, 6
beta1_ls = c(1, 2, 3, 4, 5, 6)
beta1_char = as.character(beta1_ls)
names(beta1_ls) = beta1_char
names(beta1_char) = beta1_char
# apply sim_ite to each beta1 value using a map statement
beta1_df = map_df(.x = beta1_ls, ~ sim_ite(beta1 = .x), .id = "beta1")
# write a function to compute the proportion of times the null was rejected
power_count = function(df, size) {
  temp_df = filter(df, beta1 == size)
  temp_count = sum(temp_df$p_value < 0.05)
  temp_prop = temp_count/nrow(temp_df)
  temp_prop
}
# apply power_count to each beta1 value using a map statement
power_vec = map_dbl(.x = beta1_char, ~ power_count(df = beta1_df, size = .x), .id = "beta1")
power_df = tibble(beta1 = names(power_vec), power = power_vec)
power_df$beta1 = as.integer(power_df$beta1)
ggplot(power_df, aes(x = beta1, y = power)) + 
  geom_point() + 
  geom_text(aes(label = round(power, digits = 3)), vjust = rep(-0.5, each = 6)) +
  # title, label and caption
  labs(
    title = "Proportion of times the null was rejected vs True value of beta1",
    x = "True value of beta1",
    y = "Power"
  )
```

From the plot, we can conclude that for any given population standard deviation, the greater the difference between the means of the null and alternative distributions (true value of beta1/effect size), the greater the power.

```{r Problem3Part2}
# write a function to compute the average estimate of beta1_hat
mean_estimate = function(df, size) {
  temp_df = filter(df, beta1 == size)
  temp_mean = mean(temp_df$beta1_hat)
  temp_mean
}
# apply mean_estimate to each beta1 value using a map statement
mean_vec = map_dbl(.x = beta1_char, ~ mean_estimate(df = beta1_df, size = .x), .id = "beta1")
mean_df = tibble(beta1 = names(mean_vec), mean = mean_vec)
mean_df$beta1 = as.integer(mean_df$beta1)
ggplot(mean_df, aes(x = beta1, y = mean)) + 
  geom_point() +
  geom_text(aes(label = round(mean, digits = 2)), vjust = rep(-0.5, each = 6)) +
  # title, label and caption
  labs(
    title = "Average estimate of beta1_hat vs True value of beta1",
    x = "True value of beta1",
    y = "Average estimate of beta1_hat"
  )
# write a function to compute the average estimate of beta1_hat for which the null was rejected
null_estimate = function(df, size) {
  temp_df = filter(df, beta1 == size & p_value < 0.05)
  temp_mean = mean(temp_df$beta1_hat)
  temp_mean
}
# apply mean_estimate to each beta1 value using a map statement
null_vec = map_dbl(.x = beta1_char, ~ null_estimate(df = beta1_df, size = .x), .id = "beta1")
null_df = tibble(beta1 = names(null_vec), mean = null_vec)
null_df$beta1 = as.integer(mean_df$beta1)
ggplot(null_df, aes(x = beta1, y = mean)) + 
  geom_point() +
  geom_text(aes(label = round(mean, digits = 2)), vjust = rep(-0.5, each = 6)) +
  # title, label and caption
  labs(
    title = "Average estimate of beta1_hat (rejected H0) vs True value of beta1",
    x = "True value of beta1",
    y = "Average estimate of beta1_hat"
  )
```

The sample average of beta1_hat across tests for which the null is rejected is not approximately equal to the true value of beta1. In fact, it is further away from the true value of beta1 compared to the sample average of beta1_hat for all tests. The reason why is because a smaller p-value indicates that the beta1 is more significantly different from 0. In other words, tests for which the null is rejected, corresponding to smaller p-values, have beta_hat values greater than tests for which the null is not rejected.




